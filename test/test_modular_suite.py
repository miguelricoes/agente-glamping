# Suite completa de tests unitarios para arquitectura modular
# Ejecuta todos los tests de la refactorizaciÃ³n en orden lÃ³gico

import sys
import os
import subprocess
import time
from typing import List, Dict, Any

# Agregar directorio padre al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Configurar encoding para Windows
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8', errors='ignore')

class ModularTestSuite:
    """
    Suite de tests para arquitectura modular
    Ejecuta y reporta resultados de todos los tests modulares
    """
    
    def __init__(self):
        self.test_files = [
            {
                'file': 'test_database_config.py',
                'description': 'ConfiguraciÃ³n centralizada de base de datos',
                'category': 'config',
                'priority': 'high'
            },
            {
                'file': 'test_database_service.py',
                'description': 'Servicio centralizado de base de datos',
                'category': 'services',
                'priority': 'high'
            },
            {
                'file': 'test_availability_service.py',
                'description': 'Servicio especializado de disponibilidades',
                'category': 'services',
                'priority': 'high'
            },
            {
                'file': 'test_validation_service.py',
                'description': 'Servicio centralizado de validaciÃ³n',
                'category': 'services',
                'priority': 'high'
            },
            {
                'file': 'test_user_service.py',
                'description': 'Servicio centralizado de usuarios',
                'category': 'services',
                'priority': 'high'
            },
            {
                'file': 'test_api_routes.py',
                'description': 'Rutas API centralizadas',
                'category': 'routes',
                'priority': 'medium'
            },
            {
                'file': 'test_database_config_integration.py',
                'description': 'IntegraciÃ³n de configuraciÃ³n de BD',
                'category': 'integration',
                'priority': 'medium'
            },
            {
                'file': 'test_database_integration.py',
                'description': 'IntegraciÃ³n de servicio de BD',
                'category': 'integration',
                'priority': 'medium'
            },
            {
                'file': 'test_availability_integration.py',
                'description': 'IntegraciÃ³n de servicio de disponibilidades',
                'category': 'integration',
                'priority': 'medium'
            },
            {
                'file': 'test_api_routes_integration.py',
                'description': 'IntegraciÃ³n de rutas API',
                'category': 'integration',
                'priority': 'medium'
            }
        ]
        
        self.results = []
        self.start_time = None
        self.end_time = None
    
    def run_single_test(self, test_file: Dict[str, str]) -> Dict[str, Any]:
        """
        Ejecutar un test individual
        
        Args:
            test_file: InformaciÃ³n del archivo de test
            
        Returns:
            Diccionario con resultados del test
        """
        print(f"\n{'='*80}")
        print(f"ðŸ§ª EJECUTANDO: {test_file['description']}")
        print(f"ðŸ“ Archivo: {test_file['file']}")
        print(f"ðŸ·ï¸ CategorÃ­a: {test_file['category'].upper()}")
        print(f"{'='*80}")
        
        start_time = time.time()
        
        try:
            # Ejecutar test como subprocess para capturar salida
            result = subprocess.run(
                [sys.executable, f"test/{test_file['file']}"],
                cwd=os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                capture_output=True,
                text=True,
                timeout=120  # Timeout de 2 minutos por test
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            # Analizar resultado
            success = result.returncode == 0
            
            # Extraer informaciÃ³n de la salida
            output_lines = result.stdout.split('\n') if result.stdout else []
            error_lines = result.stderr.split('\n') if result.stderr else []
            
            # Buscar informaciÃ³n de resumen
            tests_passed = 0
            tests_total = 0
            success_percentage = 0
            
            for line in output_lines:
                if 'Tests pasados:' in line:
                    try:
                        parts = line.split('Tests pasados:')[1].strip().split('/')
                        tests_passed = int(parts[0])
                        tests_total = int(parts[1])
                    except:
                        pass
                elif 'Porcentaje de Ã©xito:' in line:
                    try:
                        success_percentage = float(line.split(':')[1].strip().replace('%', ''))
                    except:
                        pass
            
            test_result = {
                'file': test_file['file'],
                'description': test_file['description'],
                'category': test_file['category'],
                'priority': test_file['priority'],
                'success': success,
                'duration': duration,
                'tests_passed': tests_passed,
                'tests_total': tests_total,
                'success_percentage': success_percentage,
                'output': result.stdout,
                'errors': result.stderr,
                'returncode': result.returncode
            }
            
            # Mostrar resultado inmediato
            if success:
                print(f"âœ… {test_file['description']}: PASÃ“")
                if tests_total > 0:
                    print(f"   ðŸ“Š Tests: {tests_passed}/{tests_total} ({success_percentage:.1f}%)")
                print(f"   â±ï¸ DuraciÃ³n: {duration:.2f}s")
            else:
                print(f"âŒ {test_file['description']}: FALLÃ“")
                print(f"   â±ï¸ DuraciÃ³n: {duration:.2f}s")
                print(f"   ðŸ”´ CÃ³digo de retorno: {result.returncode}")
                if result.stderr:
                    print(f"   ðŸš¨ Errores: {result.stderr[:200]}...")
            
            return test_result
            
        except subprocess.TimeoutExpired:
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"â° {test_file['description']}: TIMEOUT")
            print(f"   â±ï¸ DuraciÃ³n: {duration:.2f}s (lÃ­mite: 120s)")
            
            return {
                'file': test_file['file'],
                'description': test_file['description'],
                'category': test_file['category'],
                'priority': test_file['priority'],
                'success': False,
                'duration': duration,
                'tests_passed': 0,
                'tests_total': 0,
                'success_percentage': 0,
                'output': '',
                'errors': 'Test timeout after 120 seconds',
                'returncode': -1
            }
            
        except Exception as e:
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"ðŸ’¥ {test_file['description']}: ERROR")
            print(f"   ðŸš¨ Error: {str(e)}")
            print(f"   â±ï¸ DuraciÃ³n: {duration:.2f}s")
            
            return {
                'file': test_file['file'],
                'description': test_file['description'],
                'category': test_file['category'],
                'priority': test_file['priority'],
                'success': False,
                'duration': duration,
                'tests_passed': 0,
                'tests_total': 0,
                'success_percentage': 0,
                'output': '',
                'errors': str(e),
                'returncode': -2
            }
    
    def run_all_tests(self) -> bool:
        """
        Ejecutar toda la suite de tests
        
        Returns:
            True si todos los tests pasaron, False en caso contrario
        """
        self.start_time = time.time()
        
        print("ðŸš€ INICIANDO SUITE COMPLETA DE TESTS MODULARES")
        print("=" * 100)
        print(f"ðŸ“‹ Total de tests a ejecutar: {len(self.test_files)}")
        print(f"ðŸ•’ Hora de inicio: {time.strftime('%H:%M:%S')}")
        print("=" * 100)
        
        # Ejecutar tests por categorÃ­a
        categories = ['config', 'services', 'routes', 'integration']
        
        for category in categories:
            category_tests = [t for t in self.test_files if t['category'] == category]
            
            if category_tests:
                print(f"\nðŸ”§ CATEGORÃA: {category.upper()}")
                print("-" * 60)
                
                for test_file in category_tests:
                    result = self.run_single_test(test_file)
                    self.results.append(result)
        
        self.end_time = time.time()
        
        # Generar reporte final
        return self.generate_final_report()
    
    def generate_final_report(self) -> bool:
        """
        Generar reporte final de resultados
        
        Returns:
            True si todos los tests pasaron
        """
        total_duration = self.end_time - self.start_time
        
        print("\n" + "=" * 100)
        print("ðŸ“Š REPORTE FINAL DE SUITE DE TESTS MODULARES")
        print("=" * 100)
        
        # EstadÃ­sticas generales
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results if r['success'])
        failed_tests = total_tests - passed_tests
        overall_success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"ðŸŽ¯ RESUMEN GENERAL:")
        print(f"   âœ… Tests pasados: {passed_tests}/{total_tests}")
        print(f"   âŒ Tests fallados: {failed_tests}")
        print(f"   ðŸ“ˆ Tasa de Ã©xito: {overall_success_rate:.1f}%")
        print(f"   â±ï¸ DuraciÃ³n total: {total_duration:.2f}s")
        print(f"   ðŸ•’ Tiempo promedio por test: {total_duration/total_tests:.2f}s")
        
        # Desglose por categorÃ­a
        print(f"\nðŸ“‹ DESGLOSE POR CATEGORÃA:")
        categories = {}
        for result in self.results:
            cat = result['category']
            if cat not in categories:
                categories[cat] = {'total': 0, 'passed': 0, 'duration': 0}
            categories[cat]['total'] += 1
            if result['success']:
                categories[cat]['passed'] += 1
            categories[cat]['duration'] += result['duration']
        
        for cat, stats in categories.items():
            success_rate = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0
            print(f"   ðŸ”§ {cat.upper()}: {stats['passed']}/{stats['total']} ({success_rate:.1f}%) - {stats['duration']:.2f}s")
        
        # Desglose por prioridad
        print(f"\nðŸŽ¯ DESGLOSE POR PRIORIDAD:")
        priorities = {}
        for result in self.results:
            pri = result['priority']
            if pri not in priorities:
                priorities[pri] = {'total': 0, 'passed': 0}
            priorities[pri]['total'] += 1
            if result['success']:
                priorities[pri]['passed'] += 1
        
        for pri, stats in priorities.items():
            success_rate = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0
            print(f"   ðŸš€ {pri.upper()}: {stats['passed']}/{stats['total']} ({success_rate:.1f}%)")
        
        # Tests individuales
        print(f"\nðŸ“ RESULTADOS DETALLADOS:")
        for result in self.results:
            status = "âœ… PASÃ“" if result['success'] else "âŒ FALLÃ“"
            individual_stats = ""
            if result['tests_total'] > 0:
                individual_stats = f" - {result['tests_passed']}/{result['tests_total']} ({result['success_percentage']:.1f}%)"
            
            print(f"   {status} {result['description']} ({result['duration']:.2f}s){individual_stats}")
        
        # Tests fallidos en detalle
        failed_results = [r for r in self.results if not r['success']]
        if failed_results:
            print(f"\nðŸš¨ ANÃLISIS DE FALLOS:")
            for result in failed_results:
                print(f"   âŒ {result['file']}:")
                print(f"      - DescripciÃ³n: {result['description']}")
                print(f"      - CÃ³digo retorno: {result['returncode']}")
                if result['errors']:
                    error_preview = result['errors'][:200].replace('\n', ' ')
                    print(f"      - Error: {error_preview}...")
        
        # Resumen final
        print(f"\nðŸŽ‰ RESULTADO FINAL:")
        if passed_tests == total_tests:
            print("   âœ… Â¡TODOS LOS TESTS DE LA SUITE MODULAR PASARON!")
            print("   ðŸ† La refactorizaciÃ³n estÃ¡ completamente validada")
            print("   ðŸš€ Arquitectura modular lista para producciÃ³n")
            print("\nðŸŽ¯ ARQUITECTURA MODULAR VALIDADA:")
            print("   â€¢ âœ… ConfiguraciÃ³n centralizada de base de datos")
            print("   â€¢ âœ… Servicios especializados (Database, Availability, Validation, User)")
            print("   â€¢ âœ… Rutas API centralizadas y organizadas")
            print("   â€¢ âœ… IntegraciÃ³n completa y funcionando")
            print("   â€¢ âœ… Tests comprehensivos y pasando")
            print("   â€¢ âœ… Logging estructurado implementado")
            print("   â€¢ âœ… Compatibilidad hacia atrÃ¡s mantenida")
            print("   â€¢ âœ… ValidaciÃ³n centralizada de datos")
            print("   â€¢ âœ… GestiÃ³n robusta de usuarios")
            print("   â€¢ âœ… Herramientas RAG organizadas")
            return True
        else:
            print(f"   âŒ {failed_tests} TESTS FALLARON")
            print("   ðŸ”§ Revisa los fallos antes de continuar")
            print("   ðŸ“‹ Considera ejecutar tests individuales para debugging")
            return False
    
    def run_quick_validation(self) -> bool:
        """
        Ejecutar validaciÃ³n rÃ¡pida solo de tests crÃ­ticos
        
        Returns:
            True si los tests crÃ­ticos pasaron
        """
        critical_tests = [t for t in self.test_files if t['priority'] == 'high']
        
        print("âš¡ EJECUTANDO VALIDACIÃ“N RÃPIDA (TESTS CRÃTICOS)")
        print("=" * 70)
        print(f"ðŸ“‹ Tests crÃ­ticos: {len(critical_tests)}")
        
        self.start_time = time.time()
        
        for test_file in critical_tests:
            result = self.run_single_test(test_file)
            self.results.append(result)
        
        self.end_time = time.time()
        
        passed = sum(1 for r in self.results if r['success'])
        total = len(self.results)
        
        print(f"\nâš¡ RESULTADO VALIDACIÃ“N RÃPIDA:")
        print(f"   âœ… Tests crÃ­ticos pasados: {passed}/{total}")
        
        if passed == total:
            print("   ðŸŽ‰ Â¡VALIDACIÃ“N RÃPIDA EXITOSA!")
            return True
        else:
            print("   âŒ Fallos en tests crÃ­ticos")
            return False

def main():
    """FunciÃ³n principal para ejecutar la suite"""
    suite = ModularTestSuite()
    
    # Verificar argumentos de lÃ­nea de comandos
    if len(sys.argv) > 1 and sys.argv[1] == '--quick':
        success = suite.run_quick_validation()
    else:
        success = suite.run_all_tests()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()